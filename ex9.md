# Exercise 9: Batch Inferencing with Pipelines

## Before You Start

Before you start this exercise, ensure that you have completed the [previous execise](ex8.md).

## Task 1: Create an Azure ML Pipeline for Batch Inferencing

Rather than *real-time inferencing* via a web service, many organizations rely on *batch inferencing*; in which large volumes of data are processed as a batch to get predictions from a model. With Azure ML, you can use a pipeline to accomplish this.

1. Start your Notebook VM and connect to **Jupyter** or **JupyterLab**.
2. In the **/azureml-primers/notebooks** folder, open the **09 - Batch Inferencing with Pipelines (Parallel Step Preview).ipynb** notebook.
3. Read the notes in the notebook, running each code cell in turn.

> **Note**: If you intend to continue straight to the [next exercise](ex10.md), leave your Notebook VM running. If you're taking a break, you might want to close the Jupyter tabs and **Stop** your Notebook VM to avoid incurring unnecessary costs.
