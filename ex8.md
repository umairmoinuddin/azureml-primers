# Exercise 8: Batch Inferencing with Pipelines

## Before You Start

Before you start this exercise, ensure that you have completed the [previous execise](ex7.md).

## Task 1: Create an Azure ML Pipeline for Batch Inferencing

Rather than *real-time inferencing* via a web service, many organizations rely on *batch inferencing*; in which large volumes of data is processed as a batch to get predictions from a model. With Azure ML, you can use a pipeline to accomplish this.

1. Start your Notebook VM and connect to **Jupyter** or **JupyterLab**.
2. In the **/azureml-primers/notebooks** folder, open the **08 - Batch Inferencing with Pipelines.ipynb** notebook.
3. Read the notes in the notebook, running each code cell in turn.

> **Note**: If you intend to continue exploring Azure ML, leave your Notebook VM running. If you're finished, or just taking a break, you might want to close the Jupyter tabs and **Stop** your Notebook VM to avoid incurring unnecessary costs.
